{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes the non-interactive (API) [European Commission's PVGIS tool](https://ec.europa.eu/jrc/en/pvgis) to download hourly PV performance data for 2016. As the tool allows sampling of any coordinate, the resolution of hourly wind & PV performance data is restricted by the resolution of the MERRA wind data, which has a resolution of  0.5 x 0.625°. Thus, the points of interest are first obtained from the MERRA wind datasets: for each country, the downloaded MERRA coordinate points are extracted.\n",
    "\n",
    "Then, PVGIS API is utilized to extract the following features for each coordinate point (see: [API reference](https://ec.europa.eu/jrc/en/PVGIS/docs/noninteractive) and [output documentation](https://ec.europa.eu/jrc/en/PVGIS/tools/hourly-radiation)):\n",
    "- <b>Wh [Wh] -</b> hourly power output of a PV installation per kW of installed capacity of optimally aligned single horizontal axis aligned north-south PV panels ([datasources and calculation methods](https://ec.europa.eu/jrc/en/PVGIS/docs/methods))\n",
    "- <b>G(i) [W/m2] -</b> Global in-plane irradiance\n",
    "- <b>H_sun [º] -</b> Sun height (elevation)\n",
    "- <b>T2m [°C] -</b> Air temperature\n",
    "- <b>WS10m [m/s] -</b> Wind speed at 10m\n",
    "\n",
    "System assumptions:\n",
    "- PV panels are optimally aligned single horizontal axis aligned north-south panels\n",
    "- Sum of system losses = 14% <font color=red>(this should be reviewed?)</font>\n",
    "\n",
    "The databases used to calculate radiation depend on the location being queried: PVGIS-SARAH for most of Europe and PVGIS-ERA5 for European latitudes above 60 N. See more the \"raddatabase\" parameter description in the [API reference](https://ec.europa.eu/jrc/en/PVGIS/docs/noninteractive) and chapter 3 of the [PVGIS users manual](https://ec.europa.eu/jrc/en/PVGIS/docs/usermanual#fig:default_db).\n",
    "\n",
    "The results are saved as parquet files for each country in:  \n",
    "*/LAV/EnergySystemsGroup/Research/Aviation/SAFlogistics/data/PVGIS*\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import multiprocessing as mp\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(process)d - %(levelname)s: %(message)s')\n",
    "file_handler1 = logging.FileHandler('/home/saskia/Documents/Master_Thesis/logs/N03_PVGIS_download_persistent.log')\n",
    "file_handler1.setLevel(logging.INFO)\n",
    "file_handler1.setFormatter(formatter)\n",
    "file_handler2 = logging.FileHandler('/home/saskia/Documents/Master_Thesis/logs/N03_PVGIS_download.log',mode='w')\n",
    "file_handler2.setLevel(logging.DEBUG)\n",
    "file_handler2.setFormatter(formatter)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.ERROR)\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler1)\n",
    "logger.addHandler(file_handler2)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propogate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe_points = gpd.read_file('/home/saskia/Documents/Master_Thesis/data/Countries_WGS84/Europe_Evaluation_Points.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_EFTA = list(pd.read_csv('/home/saskia/Documents/Master_Thesis/data/EU_EFTA_Countries.csv',index_col=0).country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {} # Holds the DataFrames of the extracted data\n",
    "problem_points = [] # These points encountered a problem on their first API request attempt\n",
    "error_points = [] # These points encountered a problem on their second API request attempt\n",
    "sea_points = [] # These points were found to be over the sea\n",
    "\n",
    "async def download_data(point,PV_eval_loc,sema,session):\n",
    "    parameters = {\n",
    "                    'startyear':2016,\n",
    "                    'endyear':2016,\n",
    "                    'pvcalculation':1, # Nominal power of the PV system, in kW.\n",
    "                    'peakpower':1,\n",
    "                    'loss':14,\n",
    "                    'trackingtype':1,\n",
    "                    'optimalinclination':1,\n",
    "                    'outputformat':'json'\n",
    "                    }\n",
    "    parameters['lat']=str(PV_eval_loc[0]); parameters['lon']=str(PV_eval_loc[1])\n",
    "    async with sema:\n",
    "        async with session.get('https://re.jrc.ec.europa.eu/api/seriescalc',params=parameters) as resp:\n",
    "            status = resp.status\n",
    "            try:\n",
    "                response = await resp.json()\n",
    "                if status == 200: # 200 means the request returned a response correctly. all others indicate an error\n",
    "                    df = pd.DataFrame(pd.json_normalize(response['outputs']['hourly']))\n",
    "                    df['lat'] = point[0]\n",
    "                    df['lon'] = point[1]\n",
    "                    results_dict[point] = df\n",
    "                    print(results_dict)\n",
    "                else: \n",
    "                    if 'sea' in response['message']:\n",
    "                        # If the point was found to be over the sea, the message will indicate that\n",
    "                        sea_points.append(point)\n",
    "                    elif point not in problem_points:\n",
    "                        # If the point wasn't already in the problem_points list, add it now\n",
    "                        problem_points.append(point)\n",
    "                    else:\n",
    "                        # If the point was already in the problem_points list, this is the second time it has been queried and it is now considered an error point\n",
    "                        problem_points.remove(point)\n",
    "                        error_points.append(point)\n",
    "                        logger.warning(f'Error with {point}. Point not saved')\n",
    "            except aiohttp.client_exceptions.ClientPayloadError as e:\n",
    "                if point not in problem_points:\n",
    "                    problem_points.append(point)\n",
    "                else:\n",
    "                    problem_points.remove(point)\n",
    "                    error_points.append(point)\n",
    "                    logger.error(f'Error with {point}: {type(e)}. {e}. Point not saved.')\n",
    "\n",
    "async def main(country_points):\n",
    "    tasks = []\n",
    "    sema = asyncio.Semaphore(10) # Limits the number of asynchronous calls to the API possible. Try lowering this number if you encounter connection issues\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for idx in country_points.index:\n",
    "            point = idx\n",
    "            PV_eval_loc = (country_points.loc[idx,'PV_lat'],country_points.loc[idx,'PV_lon'])\n",
    "            task = asyncio.ensure_future(download_data(point,PV_eval_loc,sema,session))\n",
    "            tasks.append(task)\n",
    "        responses = asyncio.gather(*tasks)\n",
    "        await responses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Notice: Running the following cell will query the API and save the results to files\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All queries finished\n"
     ]
    }
   ],
   "source": [
    "for i,country in enumerate(EU_EFTA):\n",
    "    # --- Setup ---\n",
    "    if os.path.isfile('/home/saskia/Documents/Master_Thesis/data/PVGIS/'+country+'_PV.parquet.gzip'):\n",
    "        logger.info(f'{country} file already found.')\n",
    "        continue\n",
    "    logger.info(f'Starting {country}...')\n",
    "    country_points = europe_points.loc[europe_points.name==country].set_index(['lat','lon'])\n",
    "    logger.info(f'{len(country_points)} points will be queried for {country}')\n",
    "    stime = time.time()\n",
    "    results_dict.clear()\n",
    "    problem_points.clear()\n",
    "    sea_points.clear()\n",
    "    error_points.clear()\n",
    "    if len(results_dict)+ len(problem_points) + len(sea_points) + len(error_points) > 0:\n",
    "        logger.error(f'Lists or dictionaries not cleared properly during {country} evaluation.')\n",
    "        break\n",
    "    \n",
    "    # --- Run queries ---\n",
    "    await main(country_points)\n",
    "    # --- Retry queries for problem points\n",
    "    while len(problem_points)>0:\n",
    "        await main(country_points.loc[country_points.index.isin(problem_points)])\n",
    "\n",
    "    # --- Log results ---\n",
    "    logger.info(f'Queries finished after {time.time()-stime:.1f} seconds')\n",
    "    logger.info(f'{len(sea_points)} sea points for {country}')\n",
    "    logger.info(f'{len(problem_points)} unresolved problem points for {country}')\n",
    "    logger.info(f'{len(error_points)} error points for {country}')\n",
    "    logger.info(f'{len(results_dict)} points were succesfully queried for {country} (out of {len(country_points)}).')\n",
    "\n",
    "    # --- Concatenate the data returned for each point into a single dataframe (results_df) ---\n",
    "    if len(results_dict)>0:\n",
    "        results_df = pd.concat(results_dict.values())\n",
    "        # Rename \"P\" (power, [Watt per kW installed]) column to 'Wh' (energy produced during the given hour, [Watt-hour per kW installed])\n",
    "        results_df.rename(columns={'P':'Wh'},inplace=True)\n",
    "        results_df['time'] = pd.to_datetime(results_df['time'],format='%Y%m%d:%H%M')\n",
    "        results_df.set_index(['lat','lon','time'],inplace=True)\n",
    "        results_df.sort_index(inplace=True)\n",
    "        \n",
    "        # --- Check for errors ---\n",
    "        results_points = list(results_df.index.droplevel(2).unique())\n",
    "        wrong_points = [x for x in results_points if x not in country_points.index]\n",
    "        if len(wrong_points) > 0:\n",
    "            logger.error(f'{len(wrong_points)} wrong points were saved for {country}.')\n",
    "            break\n",
    "    else: # For some countries, it is possible that the queries return no successful responses. For these, we create an empty dataframe\n",
    "        results_df = pd.DataFrame({'lat':[],'lon':[],'time':[],'Wh':[],'G(i)':[],'H_sun':[],'T2m':[],'WS10m':[],'Int':[]})\n",
    "        results_df.set_index(['lat','lon','time'],inplace=True)\n",
    "\n",
    "    # --- Save the results to a file ---\n",
    "    results_df.to_parquet('/home/saskia/Documents/Master_Thesis/data/PVGIS/'+country+'_PV.parquet.gzip',compression='gzip')\n",
    "    logger.info(f'{country} file saved.')\n",
    "    logger.info(f'{country} finished after {time.time()-stime:.1f} seconds')\n",
    "logger.info('All queries finished')\n",
    "print('All queries finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fdd3860e",
   "language": "python",
   "display_name": "PyCharm (Master Thesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}