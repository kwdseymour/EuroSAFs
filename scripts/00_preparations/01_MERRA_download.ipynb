{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to download files from [MERRA-2](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/) (referred to as MERRA).\n",
    "\n",
    "The MERRA dataset used, [M2T1NXSLV.5.12.4](https://disc.gsfc.nasa.gov/datasets/M2T1NXSLV_5.12.4/summary) ([DOCUMENTATION](https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf)), contains historic northward and eastward wind components at multiple heights for locations across the globe. The resolution of the MERRA grid is 0.5 x 0.625°. In this notebook, the wind speeds at 10 m (U/V10M corresponds to 10 meters above the zero-plane displacement height) and 50 m (U/V50M corresponds to 50 meters above Earth's surface) are extracted, as well as the zero-plane displacement height (DISPH). \n",
    "\n",
    "The code is adapted from the [weather_data](https://github.com/Open-Power-System-Data/weather_data) package and MERRA's [help page](https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Use%20the%20Web%20Services%20API%20for%20Subsetting).\n",
    "\n",
    "For each country given, the nearest MERRA point is identified and the hourly data for all points in each day of 2016 is downloaded to a file in a folder named according to the country.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import geopandas as gpd\n",
    "import urllib\n",
    "import getpass\n",
    "import requests\n",
    "import os\n",
    "from http.cookiejar import CookieJar\n",
    "import time\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(process)d - %(levelname)s: %(message)s')\n",
    "file_handler1 = logging.FileHandler('/home/saskia/Documents/Master_Thesis/logs/N02_MERRA_download_persistent.log')\n",
    "file_handler1.setLevel(logging.INFO)\n",
    "file_handler1.setFormatter(formatter)\n",
    "file_handler2 = logging.FileHandler('/home/saskia/Documents/Master_Thesis/logs/N02_MERRA_download.log',mode='w')\n",
    "file_handler2.setLevel(logging.DEBUG)\n",
    "file_handler2.setFormatter(formatter)\n",
    "logger.addHandler(file_handler1)\n",
    "logger.addHandler(file_handler2)\n",
    "logger.propogate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Download raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part defines the input parameters according to the user and creates an URL that can download the desired MERRA-2 data via the OPeNDAP interface (see <a href=\"documentation.ipynb\">documentation notebook</a> for information on OPeNDAP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geography coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of desired coordinates. The user has to input two corner coordinates \n",
    "of a rectangular area (Format WGS84, decimal system).\n",
    "* Southwest coordinate: lat_1, lon_1\n",
    "* Northeast coordinate: lat_2, lon_2\n",
    "\n",
    "The area/coordinates will be converted from lat/lon to the MERRA-2 grid coordinates.\n",
    "Since the resolution of the MERRA-2 grid is 0.5 x 0.625°, the given exact coordinates will \n",
    "matched as close as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input of coordinates\n",
    "# ------\n",
    "# Example: Germany (lat/lon)\n",
    "# Northeastern point: 55.05917°N, 15.04361°E\n",
    "# Southwestern point: 47.27083°N, 5.86694°E\n",
    "\n",
    "# It is important to make the southwestern coordinate lat_1 and lon_1 since\n",
    "# the MERRA-2 portal requires it!\n",
    "\n",
    "def translate_lat_to_geos5_native(latitude):\n",
    "    \"\"\"\n",
    "    The source for this formula is in the MERRA2 \n",
    "    Variable Details - File specifications for GEOS pdf file.\n",
    "    The Grid in the documentation has points from 1 to 361 and 1 to 576.\n",
    "    The MERRA-2 Portal uses 0 to 360 and 0 to 575.\n",
    "    latitude: float Needs +/- instead of N/S\n",
    "    \"\"\"\n",
    "    return ((latitude + 90) / 0.5)\n",
    "\n",
    "def translate_lon_to_geos5_native(longitude):\n",
    "    \"\"\"See function above\"\"\"\n",
    "    return ((longitude + 180) / 0.625)\n",
    "\n",
    "def find_closest_coordinate(calc_coord, coord_array):\n",
    "    \"\"\"\n",
    "    Since the resolution of the grid is 0.5 x 0.625, the 'real world'\n",
    "    coordinates will not be matched 100% correctly. This function matches \n",
    "    the coordinates as close as possible. \n",
    "    \"\"\"\n",
    "    # np.argmin() finds the smallest value in an array and returns its\n",
    "    # index. np.abs() returns the absolute value of each item of an array.\n",
    "    # To summarize, the function finds the difference closest to 0 and returns \n",
    "    # its index. \n",
    "    index = np.abs(coord_array-calc_coord).argmin()\n",
    "    return coord_array[index]\n",
    "\n",
    "def get_MERRA_coordinates(SW_coord,NE_coord):\n",
    "    '''\n",
    "    Converts WGS-84 coordinates to the CRS of the MERRA-2 grid.\n",
    "    The user has to input two corner coordinates of a rectangular area (Format WGS84, decimal system).\n",
    "\n",
    "    SW_coord: Southwest coordinate: (lat_2, lon_2)\n",
    "    NE_coord: Northeast coordinate: (lat_1, lon_1)\n",
    "    \n",
    "    The area/coordinates will be converted from lat/lon to the MERRA-2 grid coordinates. \n",
    "    Since the resolution of the MERRA-2 grid is 0.5 x 0.625°, the given exact coordinates will matched as close as possible.'''\n",
    "    \n",
    "    # Southwestern coordinate\n",
    "    lat_1 = SW_coord[0]; lon_1 = SW_coord[1]\n",
    "    # Northeastern coordinate\n",
    "    lat_2 = NE_coord[0]; lon_2 = NE_coord[1]\n",
    "    \n",
    "    # The arrays contain the coordinates of the grid used by the API.\n",
    "    # The values are from 0 to 360 and 0 to 575\n",
    "    lat_coords = np.arange(0, 361, dtype=int)\n",
    "    lon_coords = np.arange(0, 576, dtype=int)\n",
    "\n",
    "    # Translate the coordinates that define your area to grid coordinates.\n",
    "    lat_coord_1 = translate_lat_to_geos5_native(lat_1)\n",
    "    lon_coord_1 = translate_lon_to_geos5_native(lon_1)\n",
    "    lat_coord_2 = translate_lat_to_geos5_native(lat_2)\n",
    "    lon_coord_2 = translate_lon_to_geos5_native(lon_2)\n",
    "\n",
    "\n",
    "    # Find the closest coordinate in the grid.\n",
    "    lat_co_1_closest = find_closest_coordinate(lat_coord_1, lat_coords)\n",
    "    lon_co_1_closest = find_closest_coordinate(lon_coord_1, lon_coords)\n",
    "    lat_co_2_closest = find_closest_coordinate(lat_coord_2, lat_coords)\n",
    "    lon_co_2_closest = find_closest_coordinate(lon_coord_2, lon_coords)\n",
    "    \n",
    "    return [lat_co_1_closest, lon_co_1_closest, lat_co_2_closest, lon_co_2_closest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining parameter choices above/translation according to OPenDAP guidelines into URL-appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:08:56.233786",
     "start_time": "2017-07-05T19:08:56.111463"
    }
   },
   "outputs": [],
   "source": [
    "def translate_year_to_file_number(year):\n",
    "    \"\"\"\n",
    "    The file names consist of a number and a meta data string. \n",
    "    The number changes over the years. 1980 until 1991 it is 100, \n",
    "    1992 until 2000 it is 200, 2001 until 2010 it is  300 \n",
    "    and from 2011 until now it is 400.\n",
    "    \"\"\"\n",
    "    file_number = ''\n",
    "    \n",
    "    if year >= 1980 and year < 1992:\n",
    "        file_number = '100'\n",
    "    elif year >= 1992 and year < 2001:\n",
    "        file_number = '200'\n",
    "    elif year >= 2001 and year < 2011:\n",
    "        file_number = '300'\n",
    "    elif year >= 2011:\n",
    "        file_number = '400'\n",
    "    else:\n",
    "        raise Exception('The specified year is out of range.')\n",
    "    \n",
    "    return file_number\n",
    "    \n",
    "\n",
    "\n",
    "def generate_url_params(parameter, time_para, lat_para, lon_para):\n",
    "    \"\"\"Creates a string containing all the parameters in query form\"\"\"\n",
    "    parameter = map(lambda x: x + time_para, parameter)\n",
    "    parameter = map(lambda x: x + lat_para, parameter)\n",
    "    parameter = map(lambda x: x + lon_para, parameter)\n",
    "    \n",
    "    base = ','.join(parameter)\n",
    "    extension = ',lat{},time{},lon{}'.format(lat_para,time_para,lon_para)\n",
    "    return base + extension\n",
    "    \n",
    "    \n",
    "\n",
    "def generate_download_links(download_years, base_url, dataset_name, url_params):\n",
    "    \"\"\"\n",
    "    Generates the links for the download. \n",
    "    download_years: The years you want to download as array. \n",
    "    dataset_name: The name of the data set. For example tavg1_2d_slv_Nx\n",
    "    \"\"\"\n",
    "    urls = {}\n",
    "    for y in download_years: \n",
    "    # build the file_number\n",
    "        y_str = str(y)\n",
    "        file_num = translate_year_to_file_number(y)\n",
    "        for m in range(1,13):\n",
    "            # build the month string: for the month 1 - 9 it starts with a leading 0. \n",
    "            # zfill solves that problem\n",
    "            m_str = str(m).zfill(2)\n",
    "            # monthrange returns the first weekday and the number of days in a \n",
    "            # month. Also works for leap years.\n",
    "            _, nr_of_days = monthrange(y, m)\n",
    "            for d in range(1,nr_of_days+1):\n",
    "                d_str = str(d).zfill(2)\n",
    "                # Create the file name string\n",
    "                file_name = 'MERRA2_{num}.{name}.{y}{m}{d}.nc4'.format(\n",
    "                    num=file_num, name=dataset_name, \n",
    "                    y=y_str, m=m_str, d=d_str)\n",
    "                # Create the query\n",
    "                query = '{base}{y}/{m}/{name}.nc4?{params}'.format(\n",
    "                    base=base_url, y=y_str, m=m_str, \n",
    "                    name=file_name, params=url_params)\n",
    "                urls[file_name] = query\n",
    "                \n",
    "    return urls\n",
    "\n",
    "def generate_download_links_by_day(day_list, base_url, dataset_name, url_params):\n",
    "    \"\"\"\n",
    "    Generates the links for the download. \n",
    "    day_list: The days you want to download as array (yyyymmdd). \n",
    "    dataset_name: The name of the data set. For example tavg1_2d_slv_Nx\n",
    "    \"\"\"\n",
    "    urls = {}\n",
    "    for day in day_list:\n",
    "        y_str = day[:4]\n",
    "        m_str = day[4:6]\n",
    "        d_str = day[6:]\n",
    "        file_num = translate_year_to_file_number(int(y_str))\n",
    "        # Create the file name string\n",
    "        file_name = 'MERRA2_{num}.{name}.{y}{m}{d}.nc4'.format(\n",
    "            num=file_num, name=dataset_name, \n",
    "            y=y_str, m=m_str, d=d_str)\n",
    "        # Create the query\n",
    "        query = '{base}{y}/{m}/{name}.nc4?{params}'.format(\n",
    "            base=base_url, y=y_str, m=m_str, \n",
    "            name=file_name, params=url_params)\n",
    "        urls[file_name] = query\n",
    "    return urls\n",
    "\n",
    "def generate_urls(MERRA_coords,year): #daylist):\n",
    "    '''Generates a dictionary of URLs according to MERRA OPeNDAP protocol to download each the desired subsetted data \n",
    "    files for each day in the time span given.\n",
    "    '''\n",
    "    # Creates a string that looks like [start:1:end]. start and end are the lat or\n",
    "    # lon coordinates define your area.\n",
    "    requested_lat = '[{lat_1}:{lat_2}]'.format(lat_1=MERRA_coords[0], lat_2=MERRA_coords[2])\n",
    "    requested_lon = '[{lon_1}:{lon_2}]'.format(lon_1=MERRA_coords[1], lon_2=MERRA_coords[3])\n",
    "\n",
    "    requested_time = '[0:23]'\n",
    "    \n",
    "    # Generate wind URLs\n",
    "    \n",
    "    # Parameter definitions: https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf\n",
    "    requested_params = ['U10M','V10M','U50M','V50M', 'DISPH']\n",
    "    parameter = generate_url_params(requested_params, requested_time,\n",
    "                                    requested_lat, requested_lon)\n",
    "    BASE_URL = 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/'\n",
    "#     generated_URLs['wind'] = generate_download_links_by_day(daylist, BASE_URL, 'tavg1_2d_slv_Nx', parameter)\n",
    "    generated_URLs = generate_download_links(year, BASE_URL, 'tavg1_2d_slv_Nx', parameter)\n",
    "\n",
    "    return generated_URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def establish_connection(username='SaskiaAdam'):\n",
    "    '''An Earthdata account is required to download data. An account can be created here: https://urs.earthdata.nasa.gov/\n",
    "    \n",
    "    This function creates a password manager to deal with the 401 response that is returned from Earthdata Login.\n",
    "    '''\n",
    "\n",
    "    password = getpass.getpass(f'Earthdata password for {username}:')\n",
    "\n",
    "    password_manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    "\n",
    "    # Create a cookie jar for storing cookies. This is used to store and return the session cookie #given to use by the data server\n",
    "    cookie_jar = CookieJar()\n",
    "\n",
    "    # Install all the handlers.\n",
    "    opener = urllib.request.build_opener (urllib.request.HTTPBasicAuthHandler (password_manager),urllib.request.HTTPCookieProcessor (cookie_jar))\n",
    "    urllib.request.install_opener(opener)\n",
    "    \n",
    "def download_files(generated_URLs,download_path):\n",
    "    '''Open a request for the data, and download files'''\n",
    "    \n",
    "    found_files = 0\n",
    "    for file_name,URL in generated_URLs.items():\n",
    "        path = os.path.join(download_path,file_name)\n",
    "        if os.path.isfile(path):\n",
    "            found_files += 1\n",
    "        else:\n",
    "            DataRequest = urllib.request.Request(URL)\n",
    "            DataResponse = urllib.request.urlopen(DataRequest)\n",
    "\n",
    "        # Print out the result\n",
    "            DataBody = DataResponse.read()\n",
    "\n",
    "        # Save file to working directory\n",
    "            try:\n",
    "                file_ = open(path, 'wb')\n",
    "                file_.write(DataBody)\n",
    "                file_.close()\n",
    "    #                 print (file_name, \"has downloaded\")\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                 print(e)\n",
    "    if found_files > 0:\n",
    "        logger.info('{} files were already found in {} and were therefore not downloaded.'.format(found_files,download_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_subset(SW_coord,NE_coord,year,download_path):\n",
    "    '''\n",
    "    Downloads the required data files for the geographic and temporal subset provided from MERRA-2.\n",
    "    \n",
    "    SW_coord: Southwest coordinate: (lat_1, lon_1)\n",
    "    NE_coord: Northeast coordinate: (lat_2, lon_2)\n",
    "    day_list: The days you want to download as array (yyyymmdd). \n",
    "    '''\n",
    "    \n",
    "    MERRA_coords = get_MERRA_coordinates(SW_coord,NE_coord)\n",
    "    generated_URLs = generate_urls(MERRA_coords,year)\n",
    "    while True:\n",
    "        try:\n",
    "            download_files(generated_URLs,download_path)\n",
    "            break\n",
    "        except:\n",
    "            establish_connection()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      name   lat    lon                  geometry\n0  Belgium  51.0  2.500  POINT (2.50000 51.00000)\n1  Belgium  51.5  2.500  POINT (2.50000 51.50000)\n2  Belgium  51.0  3.125  POINT (3.12500 51.00000)\n3  Belgium  51.5  3.125  POINT (3.12500 51.50000)\n4  Belgium  51.5  3.750  POINT (3.75000 51.50000)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Belgium</td>\n      <td>51.0</td>\n      <td>2.500</td>\n      <td>POINT (2.50000 51.00000)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Belgium</td>\n      <td>51.5</td>\n      <td>2.500</td>\n      <td>POINT (2.50000 51.50000)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Belgium</td>\n      <td>51.0</td>\n      <td>3.125</td>\n      <td>POINT (3.12500 51.00000)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Belgium</td>\n      <td>51.5</td>\n      <td>3.125</td>\n      <td>POINT (3.12500 51.50000)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Belgium</td>\n      <td>51.5</td>\n      <td>3.750</td>\n      <td>POINT (3.75000 51.50000)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Europe country points geodataframe used to extract the MERRA points found within each country\n",
    "# This file was created in the Notebook: N01_country_boundaries.ipynb\n",
    "europe_points = gpd.read_file('/home/saskia/Documents/Master_Thesis/data/Countries_WGS84/Europe_Evaluation_Points.shp')\n",
    "coast_points = gpd.read_file('/home/saskia/Documents/Master_Thesis/data/Countries_WGS84/Coast_Evaluation_Points.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_country_files(country,download_path, year=2016):\n",
    "    '''Downloads all the files corresponding to points within the given country from MERRA. Each file contains hourly wind speed data for the point\n",
    "    for the given year and is saved into a folder named after the country.'''\n",
    "    \n",
    "    stime = time.time()\n",
    "    logger.info('Initiating download process for {}.'.format(country))\n",
    "    SW_coord = (min(europe_points.loc[europe_points.name==country].bounds.miny), min(europe_points.loc[europe_points.name==country].bounds.minx))\n",
    "    NE_coord = (max(europe_points.loc[europe_points.name==country].bounds.maxy), max(europe_points.loc[europe_points.name==country,'geometry'].bounds.maxx))\n",
    "    if not os.path.isdir(download_path):\n",
    "        os.mkdir(download_path)\n",
    "    download_subset(SW_coord,NE_coord,[year],download_path)\n",
    "    logger.info(f'{country} files available after {time.time()-stime:.1f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "establish_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Notice: Running the following cell will query the API and save the results to files\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteTraceback\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;31mRemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-66-893d53da203d>\", line 7, in download_country_files\n    SW_coord = (min(europe_points.loc[europe_points.name==country].bounds.miny), min(europe_points.loc[europe_points.name==country].bounds.minx))\nValueError: min() arg is an empty sequence\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-68-e93066b8da6a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mconcurrent_processes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mP\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcurrent_processes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mP\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdownload_country_files\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcountries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0mP\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mP\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/GIS/lib/python3.7/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    266\u001B[0m         \u001B[0;32min\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mthat\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m         '''\n\u001B[0;32m--> 268\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstarmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/GIS/lib/python3.7/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    655\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    656\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 657\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    658\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    659\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: min() arg is an empty sequence"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/saskia/anaconda3/envs/GIS/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "'''This cell uses the multiprocessing library to download data for multiple countries simultaneously. \n",
    "The number of concurrent prcesses can be increased to decrease the ammount of time required to download all the data.\n",
    "If you have slow wifi, try setting it to 4 or 5. If you download too fast, however, the data portal might ban you for a day.'''\n",
    "for country in europe_points['name'].unique().tolist():\n",
    "    download_path = '/home/saskia/Documents/Master_Thesis/data/MERRA/'+country\n",
    "    download_country_files(country, download_path)\n",
    "\n",
    "for country in coast_points['name'].unique().tolist():\n",
    "    download_path = '/home/saskia/Documents/Master_Thesis/data/MERRA/'+country+'/coast'\n",
    "    download_country_files(country, download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the dataset only has MERRA-2 grid coordinates. To translate the points\n",
    "back to \"real world\" coordinates, the data portal offers a dimension scale file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}